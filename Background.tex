%\section{Preliminaries}
%This section presents the process of CDA-AL, as well as representative data poisoning attacks developed for static (non-drift) learning environments.

\section{Background: Concept Drift Adaptation with Active Learning}
\label{Sec: Concept Drift Adaptation}
Concept drift, defined as the shift in data distribution over time, degrades model accuracy.
To counter this, CDA-AL adapts models to concept drift by actively selecting high-uncertainty samples from the testing data and retraining with them~\cite{2023-Usenix-chenyizhen,park2016active,vzliobaite2013active}.
The entire concept drift process is composed of multiple concept drift cycles.
Each cycle $n$ processes a new data batch $\bm{D}_{te}^{n}$ (unlabeled testing data collected since cycle $n-1$) through three steps:

\emph{\textbf{Step I} (\textbf{Inference})}: Victim Model $f_{\bm{\theta}_{n-1}}$ performs inference on the input $\bm{\mathrm{x}}_{i} \in \bm{D}_{te}^{n}$ and outputs the classification confidence vector $\bm{\mathrm{c}}_{i} = f_{\bm{\theta}_{n-1}} \left( \bm{\mathrm{x}}_{i} \right)$.
	The different dimensions of $\bm{\mathrm{c}}_{i}$ indicate the model's confidence that the input $\bm{\mathrm{x}}_{i}$ belongs to a specific sample label.
	The label with the highest confidence is selected as the predicted label $\overline{y}_{i}$ on the input $\bm{\mathrm{x}}_{i}$.

\emph{\textbf{Step II (Selection)}}: The uncertainty score $\bm{\mathrm{u}}_{i}$ of $\bm{\mathrm{x}}_{i}$ is measured.
	For example, uncertainty can be measured as one minus the maximum softmax output of the network~\cite{2023-Usenix-chenyizhen}:
$\bm{\mathrm{u}}_{i} = 1-\max(\bm{\mathrm{c}}_{i})$.
	High-uncertainty samples are selected from the testing data $\bm{D}_{te}^{n}$ as concept drift samples $\bm{D}_{dr}^{n}$.
	The size of $\bm{D}_{dr}^{n}$ is determined by the manual labeling capacity, referred to as the labeling budget $\beta$.
	
\emph{\textbf{Step III (Retraining)}}: 
	Then, the concept drift data $\bm{D}_{dr}^{n}$ is manually labeled to get the ground truth label and added to the existing training data $\bm{D}^{n-1}_{tr}$ to form an updated training data $\bm{D}^{n}_{tr} = \bm{D}_{tr}^{n-1} \cup \bm{D}_{dr}^{n}$.
	The victim model is retrained on the updated dataset $\bm{D}^{n}_{tr}$ by minimizing the loss over model parameters, initialized from the previous cycle's parameters $\bm{\theta}_{n-1}$:
	
	\begin{equation}
		\bm{\theta}_{n} = \arg\min_{\bm{\theta}} \sum_{\bm{\mathrm{x}}_{i} \in \bm{D}^{n}_{tr}} \mathcal{L} \left( f_{\bm{\theta}}(\bm{\mathrm{x}}_{i}), y_{i} \right) 
		\quad \text{initialized from } \bm{\theta} = \bm{\theta}_{n-1}
		\label{active learning loss}
	\end{equation}
